---
blocks:
  - quote: Models
    color: tint
    _template: testimonial
  - items:
      - icon:
          color: white
          style: circle
          name: AI4B
        title: IndicFT
        link: /indic-ft
        text: >-
          fastText is a well-suited model for Indian languages because of their
          rich morphological structure. We pre-train and benchmark fastText
          embeddings on our corpora, producing embeddings that outperform the
          official fastText embeddings for Indian languages on a variety of
          tasks.
      - icon:
          color: white
          style: circle
          name: AI4B
        title: IndicBERT
        link: /indic-bert
        text: >-
          To improve performance and coverage of Indian languages on a wide
          variety of tasks, we also develop and evaluate IndicBERT. IndicBERT is
          a multilingual ALBERT model (a lighter variant of BERT) pre-trained on
          12 major Indian languages: Assamese, Bengali, English, Gujarati,
          Hindi, Kannada, Malayalam, Marathi, Oriya, Punjabi, Tamil, Telugu. It
          provides state-of-the-art performance on some of the tasks.
      - icon:
          color: white
          style: circle
          name: AI4B
        title: IndicBART
        link: /indic-bart
        text: >-
          IndicBART is a multilingual, sequence-to-sequence pre-trained model
          focusing on Indic languages and English. It currently supports 12
          languages and is based on the mBART architecture.
      - icon:
          color: white
          style: circle
          name: AI4B
        title: IndicTrans
        link: /indic-trans
        text: >-
          A multilingual single-script transformer based model for translating
          between English and Indian languages. This model is trained using the
          Samanantar corpus and at the time of its release was the state of the
          art open source model as evaluated on Facebook's FLORES benchmark.
      - icon:
          color: white
          style: circle
          name: AI4B
        title: IndicXLit
        link: /indic-x-lit
        text: >-
          A multilingual transformer based model for transliteration from
          romanized input to native language scripts supporting 21 languages.
          This model is trained using Aksharantar corpus and at the time of its
          release was the state of the art open source model as evaluated on
          Google's Dakshina benchmark and our Aksharantar benchmark.
      - icon:
          color: white
          style: circle
          name: AI4B
        title: IndicWav2Vec
        link: /indic-wav-2-vec
        text: >
          IndicWav2Vec is a multilingual speech model pretrained on 40 Indian
          langauges. This model represents the largest diversity of Indian
          languages in the pool of multilingual speech models. We fine-tune this
          model for downstream ASR for 9 languages and obtain state-of-the-art
          results on 3 public benchmarks, namely MUCS, MSR and OpenSLR.
    _template: featuresAlt
---

