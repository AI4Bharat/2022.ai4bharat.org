---
blocks:
  - tagline: ''
    headline: IndicTrans2
    text: ''
    _template: hero
  - body: >
      [Preprint is available here](https://arxiv.org/abs/2305.16307)\



      IndicTrans2 is the first open-source transformer-based multilingual NMT
      model that supports high-quality translations across all the 22 scheduled
      Indic languages â€” including multiple scripts for low-resouce languages
      like Kashmiri, Manipuri and Sindhi. It adopts script unification wherever
      feasible to leverage transfer learning by lexical sharing between
      languages. Overall, the model supports five scripts Perso-Arabic
      (Kashmiri, Sindhi, Urdu), Ol Chiki (Santali), Meitei (Manipuri), Latin
      (English), and Devanagari (used for all the remaining languages).


      We open-souce all our training dataset (BPCC), back-translation data
      (BPCC-BT), final IndicTrans2 models, evaluation benchmarks (IN22, which
      includes IN22-Gen and IN22-Conv) and training and inference scripts for
      easier use and adoption within the research community. We hope that this
      will foster even more research in low-resource Indic languages, leading to
      further improvements in the quality of low-resource translation through
      contributions from the research community.


      This code repository contains instructions for downloading the artifacts
      associated with IndicTrans2, as well as the code for training/fine-tuning
      the multilingual NMT models.


      Here is the list of languages supported by the IndicTrans2 models:
    _template: content
---

