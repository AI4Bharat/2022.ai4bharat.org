---
blocks:
  - body: "# IndicNLG Suite\n\n***\n\nIndicNLG suite is a collection of datasets for benchmarking Natural Language Generation (NLG) for 11 Indic languages spanning five diverse NLG tasks. The datasets were created using a combination of crawling websites, machine translation, n-gram count and regular expression based cleaning . Overall, the suite contains about 8.5M examples across all languages and tasks and is the largest multilingual NLG dataset to date as well as the first of its kind for Indic languages. You can use these datasets to benchmark your own NLG systems.\n\n*   Supported languages: Assamese, Bengali, Gujarati, Hindi, Marathi, Odiya, Punjabi, Kannada, Malayalam, Tamil, and Telugu.\n*   Supported NLG tasks and datasets: Biography generation using Wikipedia infoboxes (WikiBio), news headline generation, sentence summarization, question generation and paraphrase generation.\n*   Datasets are available in json file and HuggingFace format.\n\nYou can read more about IndicNLGSuite\_[in this paper](https://arxiv.org/abs/2203.05437). We have benchmarked our own monolingual and multilingual models based on\_[IndicBART](https://indicnlp.ai4bharat.org/indic-bart)\_and found that our models perform at par with or are better than baseline models such as mT5.\n\n### Downloads\n\nThe datasets and models are available on\_[HuggingFace](https://huggingface.co/)\n\nTaskDatasetModelBiography Generation[IndicWikiBio](https://huggingface.co/datasets/ai4bharat/IndicWikiBio)Coming SoonHeadline Generation[IndicHeadlineGeneration](https://huggingface.co/datasets/ai4bharat/IndicHeadlineGeneration)Coming SoonSentence Summarization[IndicSentenceSummarization](https://huggingface.co/datasets/ai4bharat/IndicSentenceSummarization)Coming SoonParaphrase Generation[IndicParaphrase](https://huggingface.co/datasets/ai4bharat/IndicParaphrase)Coming SoonQuestion Generation[IndicQuestionGeneration](https://huggingface.co/datasets/ai4bharat/IndicQuestionGeneration)Coming Soon\n\n### IndicBART fine-tuning and decoding\n\n*   Follow the setup instructions\_[here](https://github.com/AI4Bharat/indic-bart/blob/main/README.md#installation).\n    *   We use the\_[YANMTT](https://github.com/prajdabre/yanmtt)\_toolkit for fine-tuning IndicBART.\n*   Extract the input and target text from the jsonl format files or HuggingFace format files.\n    *   For question generation, concatenate the question and context into a single line.\n    *   Convert the scripts in the extracted files into Devanagari using the\_[Indic Script Converter](https://github.com/AI4Bharat/indic-bart/blob/main/indic\\_scriptmap.py).\n*   [Here](https://github.com/AI4Bharat/indic-bart/blob/main/README.md#fine-tuning-command-1)\_is a command for fine-tuning IndicBART for summarization.\n    *   The correct input and output file paths should be provided.\n    *   Use appropriate hyperparameters according the paper.\n*   Decode the test set using the fine-tuned model after modifying\_[this](https://github.com/AI4Bharat/indic-bart/blob/main/README.md#decoding-command-1)\_command.\n    *   Map the output to the original script using the script converter.\n*   **Alternatively**: IndicBART is uploaded to HuggingFace hub\_[here](https://huggingface.co/ai4bharat/IndicBART).\n    *   Modify the HuggingFace\_[summarization](https://github.com/huggingface/transformers/tree/master/examples/pytorch/summarization)\_script to use the IndicBART model.\n    *   This script can use the json as well as HuggingFace format files.\n    *   Ensure that script mapping is done before training and after decoding.\n\n### Contributors\n\n*   Aman Kumar\n*   Prachi Sahu\n*   Himani Shrotriya\n*   Raj Dabre\n*   Ratish Puduppully\n*   Anoop Kunchukuttan\n*   Amogh Mishra\n*   Mitesh M. Khapra\n*   Pratyush Kumar\n\n### Citing\n\nIf you use IndicNLG Suite, please cite the\_[following paper](https://arxiv.org/abs/2203.05437):\n\n```\n@misc{kumar2022indicnlg,\r\n      title={IndicNLG Suite: Multilingual Datasets for Diverse NLG Tasks in Indic Languages}, \r\n      author={Aman Kumar and Himani Shrotriya and Prachi Sahu and Raj Dabre and Ratish Puduppully and Anoop Kunchukuttan and Amogh Mishra and Mitesh M. Khapra and Pratyush Kumar},\r\n      year={2022},\r\n      eprint={2203.05437},\r\n      archivePrefix={arXiv},\r\n      primaryClass={cs.CL}\r\n}   \r\n\n```\n\n### License\n\n**Datasets**\n\nDifferent datasets are released under different licenses\n\n**IndicHeadlineGeneration, IndicSentenceSummarization and IndicParaphrase**\_are licensed under a\_[Creative Commons Attribution-NonCommercial 4.0 International License](http://creativecommons.org/licenses/by-nc/4.0/).\n\n**IndicWikiBio and IndicQuestionGeneration**\_are licensed under a\_[Creative Commons Attribution-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-sa/4.0/).\n\n**Models**\n\nAll models are released under the MIT license.\n"
    _template: content
---

